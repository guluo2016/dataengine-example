### 1 下载认证文件

对于开启安全模式及权限的集群，要通过程序连接大数据集群，需要借助于认证文件。

首先需要通过集群管理平台新建一个用户，该拥有要求有读写HBase、HDFS组件的权限，以及往YARN指定队列中提交任务的权限。

用户新建成功之后，可以点击对应用户的`下载认证文件`按钮，下载该用户的认证文件，认证文件有两个，分别是`krb5.conf`和`用户名.keytab`。

### 2 获取Principal

将`用户名.keytab`文件，拷贝至集群，执行`klist -kt 用户名.keytab`，可以获取对用用户的principal。如图所示：

![image-20220105104218939](https://github.com/guluo2016/picture/raw/dev/img/image-20220105104218939.png) 

### 3 获取配置文件

程序读写HBase集群，需要集群中的相关配置文件：

- `hbase-site.xml`：可以在集群中的节点的`/usr/hdp/3.0.1.0-187/hbase/conf/`目录下获取
- `core-site.xml`和`hdfs-site.xml`：可以在集群中的节点的`/usr/hdp/3.0.1.0-187/hadoop/conf`目录下获取

### 4 配置本地hosts

将集群中hosts文件的信息配置到程序要运行的机器中。

### 5 代码运行

切换至`spark-example`目录下，执行`mvn clean package -DskipTests`，进行编译打包。将编译好的jar包拷贝至集群节点中。

在HBase中执行`create 'simple_data', info `命令，创建一个名字为`simple_data`的表。

- spark往HBase表中写入数据

  `spark-submit --master yarn --class com.h3c.spark.hbase.example.kerberos.SparkWriteHBase spark-example-1.0-SNAPSHOT.jar`

- Spark从HBase表中读取数据

  `spark-submit --master yarn --class com.h3c.spark.hbase.example.kerberos.SparkReadHBase spark-example-1.0-SNAPSHOT.jar`